{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchtext as tt\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, linear_model\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv(\"./train.csv\")\n",
    "submission = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "print(len(trainDf), len(submission))\n",
    "print(trainDf.head(5))\n",
    "print(submission.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(trainDf[\"keyword\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf[trainDf[\"target\"] == 0][\"text\"].values[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Vectorization, data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = trainDf[[\"text\", \"target\"]]\n",
    "trainDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer()\n",
    "vectorized_example = vectorizer.fit_transform(trainDf[\"text\"][0:5])\n",
    "print(vectorized_example.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_part, test_part = train_test_split(trainDf, test_size=0.2)\n",
    "\n",
    "print(train_part.shape, test_part.shape)\n",
    "\n",
    "vectorized_train = train_vectorizer.fit_transform(train_part[\"text\"])\n",
    "vectorized_test = train_vectorizer.transform(test_part[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorized_train.shape)\n",
    "print(vectorized_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train_labels = []\n",
    "for i in train_part[\"target\"]:\n",
    "    lbl = [0,0]\n",
    "    lbl[i] = 1\n",
    "    vectorized_train_labels.append(lbl)\n",
    "vectorized_test_labels = []\n",
    "for i in test_part[\"target\"]:\n",
    "    lbl = [0,0]\n",
    "    lbl[i] = 1\n",
    "    vectorized_test_labels.append(lbl)\n",
    "\n",
    "vectorized_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorized_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweetDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_size, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Linear(vocab_size, embedding_dim)\n",
    "        self.encoder = torch.nn.LSTM(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.predictor = torch.nn.Linear(hidden_size, 2)\n",
    "    \n",
    "    def forward(self, index_sequence):\n",
    "        emb = self.embedding(index_sequence)\n",
    "        #print(f\"Emb output shape 1: {emb.shape}\")\n",
    "        emb = torch.unsqueeze(emb, 2)\n",
    "        #print(f\"Emb output shape 2: {emb.shape}\")\n",
    "        output, (hidden_state, cell_state) = self.encoder(emb)\n",
    "        #print(f\"lstm output shape 1: {output.shape}\")\n",
    "        output = torch.transpose(output, 0,1)\n",
    "        #print(f\"lstm output shape 2: {output.shape}\")\n",
    "        final = self.predictor(output[-1])\n",
    "        #print(f\"Final output shape {final.shape}\")\n",
    "        return final \n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, model, optimizer, lossFn, trainLoader, validationLoader):\n",
    "    global batch_size\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        model.train()\n",
    "        for batch in trainLoader:\n",
    "            tweets, labels = batch\n",
    "            labels = torch.tensor(labels).to(torch.float32).to(device)\n",
    "            tweets = torch.tensor(tweets).to(torch.float32).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(tweets)\n",
    "            # print(tweets)\n",
    "            # print(labels)\n",
    "            #print(predict[0], predict[0])\n",
    "            loss = lossFn(predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item()\n",
    "        train_loss /= len(trainLoader)\n",
    "\n",
    "        model.eval()\n",
    "        for batch in validationLoader:\n",
    "            tweets, labels = batch\n",
    "            labels = torch.tensor(labels).to(torch.float32).to(device)\n",
    "            tweets = tweets.to(device)\n",
    "            prediction = model(tweets)\n",
    "            loss = lossFn(prediction, labels)\n",
    "            validation_loss += loss.data.item()\n",
    "        validation_loss /= len(validationLoader)\n",
    "        print(f\"Epoch: {e}, Train Loss: {round(train_loss,2)}, Validation Loss: {round(validation_loss,2)}\")\n",
    "    \n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_convert(batch):\n",
    "    tweets, labels = zip(*batch)\n",
    "    return (torch.Tensor(tweets), torch.Tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "testDataset = tweetDataset(vectorized_test, vectorized_test_labels)\n",
    "testLoader =  torch.utils.data.DataLoader(testDataset, collate_fn=collate_convert, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_3624\\2836618619.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(torch.float32).to(device)\n",
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_3624\\2836618619.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tweets = torch.tensor(tweets).to(torch.float32).to(device)\n",
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_3624\\2836618619.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.09, Validation Loss: 0.23\n",
      "saved\n",
      "609 1217\n",
      "Epoch: 0, Train Loss: 0.09, Validation Loss: 0.24\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "#Don't know why, but it does not change train indexes, so I will take them from validation indexes\n",
    "\n",
    "#model = MyLSTM(1000, 200, vectorized_train.shape[1])\n",
    "model = torch.load(\"twits_classify_LSTM_model.pth\")\n",
    "model.to(device)\n",
    "\n",
    "n_splits=10\n",
    "crossval_selection = KFold(n_splits=n_splits)\n",
    "generator = crossval_selection.split(vectorized_train)\n",
    "for _ in range(2):\n",
    "    train, validation = next(generator)\n",
    "    print(validation[0], validation[-1])\n",
    "    vtarr = vectorized_train.toarray()\n",
    "    trainDataset = tweetDataset(np.concatenate((vtarr[0:validation[0]+1], vtarr[validation[-1]:])), np.concatenate((vectorized_train_labels[0:validation[0]+1], vectorized_train_labels[validation[-1]:])))\n",
    "    trainLoader = torch.utils.data.DataLoader(trainDataset)\n",
    "\n",
    "    validationDataset = tweetDataset(vtarr[validation[0]:validation[-1]], vectorized_train_labels[validation[0]:validation[-1]])\n",
    "    validationLoader = torch.utils.data.DataLoader(validationDataset, collate_fn=collate_convert, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    epochs = 1\n",
    "    optimizer = torch.optim.ASGD(model.parameters(), lr=0.1)\n",
    "    lossFn = torch.nn.CrossEntropyLoss()\n",
    "    valLoss = train_model(epochs, model, optimizer, lossFn, trainLoader, validationLoader)\n",
    "    print(\"saved\")\n",
    "    torch.save(model, \"twits_classify_LSTM_model.pth\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {1:\"disaster\", 0:\"false alarm\"}\n",
    "\n",
    "result = pd.DataFrame(submission[\"id\"])\n",
    "target = pd.Series()\n",
    "\n",
    "model.eval()\n",
    "for i in range(0,len(submission),100):\n",
    "    output = model(torch.tensor(train_vectorizer.transform(submission[\"text\"][i:i+100]).toarray()).to(torch.float32).to(device))\n",
    "    indexes = torch.argmax(output, dim=1).to(\"cpu\")\n",
    "    target = pd.concat([target, pd.Series(indexes)])\n",
    "\n",
    "result[\"target\"] = target.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
